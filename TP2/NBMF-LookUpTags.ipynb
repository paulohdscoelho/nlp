{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leitura_arquivo(path):\n",
    "    f1 = open(path, 'r', encoding='utf8')\n",
    "    text = [[' ',' '],[' ',' '],[' ',' ']]\n",
    "    tags = []\n",
    "    #leio arquivo e crio uma lista [word,tag]\n",
    "    for line in f1:\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            text.append( token.split('_'))\n",
    "            #tags.append( token.split('_')[1])\n",
    "\n",
    "    text.append([' ',' '])\n",
    "    text.append([' ',' '])\n",
    "    text.append([' ',' '])\n",
    "    return text\n",
    "\n",
    "def words_to_num(text):\n",
    "    words = {text[0][0]: 0, text[1][0]: 0, text[2][0]: 0}\n",
    "    tags = {text[0][1]: 0, text[1][1]: 0, text[2][1]: 0}\n",
    "    \n",
    "    for i in range(3,len(text)):\n",
    "        try:\n",
    "            words[text[i][0]] = 0\n",
    "        except:\n",
    "            print (i, text[i][0])\n",
    "        tags[text[i][1]] = 0\n",
    "    \n",
    "    #agora tenho um número único para cada palavra/tag\n",
    "    return np.array(list(words.keys()) + list(tags.keys()))\n",
    "\n",
    "def cria_dict_num(num_of_words):\n",
    "    num_dict = {}\n",
    "    for i in range(len(num_of_words)):\n",
    "        num_dict[num_of_words[i]] = i\n",
    "    return num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cria_ngram(text):\n",
    "    ngram = []\n",
    "    for i in range(3,len(text)-3):\n",
    "        ngram.append([text[i-3][0],text[i-3][1], text[i-2][0],text[i-2][1], text[i-1][0],text[i-1][1], text[i][0], text[i+1][0], text[i+2][0], text[i+3][0]])\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'macmorpho-train.txt'\n",
    "text = leitura_arquivo(path)\n",
    "word_number = words_to_num(text)\n",
    "dict_num = cria_dict_num(word_number)\n",
    "flags = np.array(list(dict_num[text[i][1]] for i in range(3,len(text)-3)))\n",
    "#ngram = ['prev_prev_prev_word','prev_prev_prev_tag','prev_prev_word','prev_prev_tag','prev_word','prev_tag', 'curr_word', 'next_word','next_next_word','next_next_next_word']\n",
    "ngram = cria_ngram(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx = sparse.lil_matrix((len(ngram),len(word_number)+2), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728497, 52789)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(ngram)-2):\n",
    "    for word in ngram[i]:\n",
    "        mtx[i,dict_num[word]]+=1\n",
    "    mtx[i,len(word_number)-2] = len(ngram[i][6])\n",
    "    if ngram[i][6].islower():\n",
    "        mtx[i,len(word_number)-1] = 1\n",
    "    else:\n",
    "        mtx[i,len(word_number)-1] = 0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_x = mtx\n",
    "train_y = flags\n",
    "\n",
    "model = MultinomialNB()\n",
    "clf = model.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = clf.score(mtx,flags)\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'macmorpho-test.txt'\n",
    "text = leitura_arquivo(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gero fgram do tipo ['prev_prev_word','prev_word', 'curr_word', 'next_word']\n",
    "ngram_teste = []\n",
    "for i in range(3,len(text)-3):\n",
    "    ngram_teste.append([text[i-3][0],text[i-3][1], text[i-2][0],text[i-2][1], text[i-1][0],text[i-1][1], text[i][0], text[i+1][0], text[i+2][0], text[i+3][0]])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx = sparse.lil_matrix((len(ngram_teste),len(word_number)+2), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(ngram_teste)):\n",
    "    for word in ngram_teste[i]:\n",
    "        try:\n",
    "            mtx[i,dict_num[word]]+=1\n",
    "        except:\n",
    "            mtx[i,dict_num[' ']]+=1\n",
    "    mtx[i,len(word_number)-2] = len(ngram_teste[i][6])\n",
    "    if ngram_teste[i][6].islower():\n",
    "        mtx[i,len(word_number)-1] = 1\n",
    "    else:\n",
    "        mtx[i,len(word_number)-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags_teste = np.array(list(dict_num[text[i][1]] for i in range(3,len(text)-3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178373, 52789) 178373\n"
     ]
    }
   ],
   "source": [
    "print(mtx.shape,\n",
    "len(flags_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48591995425316614"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(mtx,flags_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
